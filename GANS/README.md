This folder contains implementations of two Generative Adversarial Networks (GAN) architectures—Fully Convolutional GAN (FCGAN) and Deep Convolutional GAN (DCGAN) built to generate realistic handwritten digits using the MNIST dataset. The FCGAN architecture is designed without any dense layers, relying entirely on convolutional and transposed convolutional layers, making it spatially aware and fully convolutional from end to end. In contrast, the DCGAN follows a more classic architecture with a dense input layer in the generator. Both models use the Adam optimizer (with β₁ = 0.5), binary cross-entropy loss, and include techniques like label smoothing for stabilizing discriminator training. The training process includes per-epoch loss tracking and fixed-noise image generation for visualizing progress. Code optimizations like `@tf.function` and `prefetch(tf.data.AUTOTUNE)` are applied for faster execution. This setup serves as a hands-on exploration of GAN behavior and performance in image synthesis tasks.

